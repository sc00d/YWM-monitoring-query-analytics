Парсинг API ЯВМ (https://yandex.ru/dev/webmaster/doc/ru/reference/host-query-analytics), как замена Топвизору (по крайней мере для позиций в Яндексе)

Вступление

Топвизор разработали классный интерфейс, удобные выгрузки и т.д., но каждый раз пополняя счет становится как-то грустно.  Опросить СЯ федерального магазина мебели по всем поддоменам, например - довольно затратно.

Для себя в качестве одной из альтернатив вижу парсинг ЯВМ API (второй конечно же A-Parser).

Плюсы парсинга API YWM:
— Бесплатно
— Позиции честнее чем в Топвизоре (за счет получения средней позиции за сутки из персонализированных выдач разных реальных юзеров)
— Данные есть по всем ключам, по которым страница ранжировалась или могла ранжироваться, а не только тем, по которым вы настроили опрос
— Есть данные не только по позициям, но и по: Кликам, CTR, Спросу, Показам
— Данные можно обрабатывать/использовать по-своему под разные задачи, в отличии от готовых сервисов.

Минусы:
— Данные доступны только за период в 14 дней. 
— Данные поступают с лагом в N дней (по разному, обычно через 2-4 дня)

В целом в ЯВМ есть готовая выгрузка в XLS, если у вас мало хостов (сайтов, с учетом поддоменов), то можете просто качать оттуда и не париться: выгружать раз в 2 недели и матчить их, если требуется история, хотя формат там из коробки ну такой себе. 

Про скрипт

Когда в работе проекты на сотни поддоменов, то качать файлы через вебинтерфейс - сомнительно. Для таких случаев накидал скрипт, который забирает по API доступные данные для всех или указанных хостов. Скрипт собирает данные и сохраняет в CSV файл (если будут потом проблемы - переписать на БД недолго), с CSV порог входа нулевой, а для мелких-средних проектов его хватит. Да и импортировать потом данные из CSV в БД легко. Запуск скрипта можно поставить на крон или просто не забывать его запускать раз в неделю-две. 

Из обязательных параметров - только ваш токен (инструкция (https://www.marronnier.ru/blog/13-avtomatizatsiya/57-indeksirovanie-sajtov-s-pomoshchyu-yandeks-vebmaster-api-na-python) как добыть его). Остальные настройки опциональны.

Если массив с HOST_ID не задан (задается массивом), то в выгрузке будут данные по всем доступным хостам, кроме тех, которые перечислены в EXCLUDED_HOSTS (тоже массив). Нюанс - задаются в формате обычных URLов - в комментах есть примеры

Данные по Path (URL, но без хоста) я не собираю, как собирается в скрипте от Ed (https://github.com/Edbaro42/ywm_mon_pos_api)'а (если кому-то надо - напишите в комментариях). Так скорость на порядок выше, что в случае с сотнями поддоменов + лимитами API - критично (для меня).  
 
Для запуска нужен питон (впрочем кому надо - может попросить переписать AI/своих разрабов на PHP или любой другой язык). Если боитесь питона - то просто загуглите Anaconda (дистрибутив Python), в нем нас интересует Jupyter Notebook, с ним запуск скриптов на питоне - одно удовольствие. Просто создать новый Notebook, копирнуть код, поменять настройки на свои и нажать Run
